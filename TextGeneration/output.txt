
runfile('C:/Users/santhob/.spyder-py3/temp.py', wdir='C:/Users/santhob/.spyder-py3')
length of text:1115394 characters
 unique characters 65
'p'    ---->  54,
'r'    ---->  56,
'C'    ---->  15,
'b'    ---->  40,
'N'    ---->  26,
'M'    ---->  25,
'o'    ---->  53,
'O'    ---->  27,
'h'    ---->  46,
'u'    ---->  59,
'v'    ---->  60,
';'    ---->  11,
'g'    ---->  45,
'V'    ---->  34,
'T'    ---->  32,
'l'    ---->  50,
'i'    ---->  47,
'y'    ---->  63,
'J'    ---->  22,
'e'    ---->  43,
First Citizen--- characters mapped to int[18 47 56 57 58  1 15 47 58 47 64 43 52]
F
i
r
s
t
'First Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou '
'are all resolved rather to die than to famish?\n\nAll:\nResolved. resolved.\n\nFirst Citizen:\nFirst, you k'
"now Caius Marcius is chief enemy to the people.\n\nAll:\nWe know't, we know't.\n\nFirst Citizen:\nLet us ki"
"ll him, and we'll have corn at our own price.\nIs't a verdict?\n\nAll:\nNo more talking on't; let it be d"
'one: away, away!\n\nSecond Citizen:\nOne word, good citizens.\n\nFirst Citizen:\nWe are accounted poor citi'
Input data:  'First Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou'
Target data: 'irst Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou '
step    0
input:18('F')
target expected output:47('i')
step    1
input:47('i')
target expected output:56('r')
step    2
input:56('r')
target expected output:57('s')
step    3
input:57('s')
target expected output:58('t')
step    4
input:58('t')
target expected output:1(' ')
<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int32, tf.int32)>
one
two
(64, 100, 65) #(batch_size,sequence_length,vocab_size)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_22 (Embedding)     (64, None, 256)           16640     
_________________________________________________________________
gru_22 (GRU)                 (64, None, 1024)          3935232   
_________________________________________________________________
dense_22 (Dense)             (64, None, 65)            66625     
=================================================================
Total params: 4,018,497
Trainable params: 4,018,497
Non-trainable params: 0
_________________________________________________________________
[48 32 24  3 20 63  3 12 60 61 15 60 40 10 44 34 37  5 50 31  5 26  9 10
  4 28  7  1  1 25  0 10 26 56 58 33 25 28 30 53 53 54 31 30 52 40 60  6
  6  8 32 32 30 13 49 58  4 26 32  6 20  3 32 60  9 13 32 24 42 44  8 64
 54 21  2  7 15 44 35 55  1  7 52 62 17 43  6 39 51 33 56 14 45 33 22  0
 14 39 10 60]
Input: 
 "His master's son, as worshipful as he terms it,\nShall lose the royalty of England's throne.\n\nBUCKING"

Next Char Predictions: 
 "jTL$Hy$?vwCvb:fVY'lS'N3:&P-  M\n:NrtUMPRoopSRnbv,,.TTRAkt&NT,H$Tv3ATLdf.zpI!-CfWq -nxEe,amUrBgUJ\nBa:v"
Prediction shape:  (64, 100, 65)  # (batch_size, sequence_length, vocab_size)
scalar_loss:       4.270338
debug1
debug2
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_23 (Embedding)     (1, None, 256)            16640     
_________________________________________________________________
gru_23 (GRU)                 (1, None, 1024)           3935232   
_________________________________________________________________
dense_23 (Dense)             (1, None, 65)             66625     
=================================================================
Total params: 4,018,497
Trainable params: 4,018,497
Non-trainable params: 0
_________________________________________________________________
debug3
debug4
ROMEO
&yC
Q;zRAhD!.!xdYLk
!zvc3:GHFjIQ:FHBIjeTpEt LHshIZTg awPyXgpvIUy
D,fFDPD'WLUutzg$caA'Z$y-wAxXj.a;lDGSiphIfSvR?cwouSXYJwmvL:yINJBKt YuYMnabPu.YztJDxBNvPyyefW-a?j;AIS-f3szbtG;LGOI:ZcNGmy
n-dWTNKZ3Te&
Zr
,KE?fec&eU3zssEgPvN.Zcz-YUQuNlPwcpvbU.E?f?pdMcBL Vqsh:Gc3u'hSYYHtt'H.UyCDN?ND
GjjLQDpBwy3GNjSzoMU-cqgUFGuNi;HFg?hRPy$W;gNK:qAWBkVVWcZH.ljLvcIpq3Nv3uMFQ-fnsQnXK!IUHPK?JAJF.wTg&DnFzf
!L.yP&: cQjBSp'svVL!JG3N?jQiQyTPhfyp
KLyTNxFpIgGdhDi3f3o-LOmxj3ZiLBoS!A$F DnVU!'r,k bIeZ,zPNii?n hguDBUHd3?sIccauGxyTya.E-tSna?ypVjGu?x-WxIZvS;'ALHjbl.XkE& Cmi!QN-oR?;jPL&N3-KuIpjn-yxSD,TdbRWvaLF.DpMa? Zebvy!qLpWmRS
'N
SjQa:Hjm
v&
;xdJvg:eG?Zua.YI?y'E;asLrD&l,vk
DoZP
fm
YHMAWUW&eI$DxRhhVulDY:Ry?iUYEIYrlJcIKU?o
pHiouSlz'JDYv,YBDbrQVfmhj&w&aK'eIS
3yM:Rv3v:iN$,'vuvgph&P3w
JZp;SZ3gwQK Sqa:xa&BCDS;IJlng &.OYF3 yDItnYAoV'?tU,K'DlwbpuHU?
c,$DpLpuDmCvr'n,gxKxYw!pSPVKuDM:wWUInGSDp-!thHcPsWbA!QTrNNKsRDJegANioZ-G:qkI'rlX!Hd hVWENivSRcg
Fy3'mMToJ?L?Bc$TnWRm.ctAoJXnR3b'3ilpfYXN;m!lT$SU-MA3iHIAmDQvS'RScj3WbtHAIHKuKy.NSjiv'Q
END

runfile('C:/Users/santhob/.spyder-py3/temp.py', wdir='C:/Users/santhob/.spyder-py3')
length of text:1115394 characters
 unique characters 65
'p'    ---->  54,
'r'    ---->  56,
'C'    ---->  15,
'b'    ---->  40,
'N'    ---->  26,
'M'    ---->  25,
'o'    ---->  53,
'O'    ---->  27,
'h'    ---->  46,
'u'    ---->  59,
'v'    ---->  60,
';'    ---->  11,
'g'    ---->  45,
'V'    ---->  34,
'T'    ---->  32,
'l'    ---->  50,
'i'    ---->  47,
'y'    ---->  63,
'J'    ---->  22,
'e'    ---->  43,
First Citizen--- characters mapped to int[18 47 56 57 58  1 15 47 58 47 64 43 52]
F
i
r
s
t
'First Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou '
'are all resolved rather to die than to famish?\n\nAll:\nResolved. resolved.\n\nFirst Citizen:\nFirst, you k'
"now Caius Marcius is chief enemy to the people.\n\nAll:\nWe know't, we know't.\n\nFirst Citizen:\nLet us ki"
"ll him, and we'll have corn at our own price.\nIs't a verdict?\n\nAll:\nNo more talking on't; let it be d"
'one: away, away!\n\nSecond Citizen:\nOne word, good citizens.\n\nFirst Citizen:\nWe are accounted poor citi'
Input data:  'First Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou'
Target data: 'irst Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou '
step    0
input:18('F')
target expected output:47('i')
step    1
input:47('i')
target expected output:56('r')
step    2
input:56('r')
target expected output:57('s')
step    3
input:57('s')
target expected output:58('t')
step    4
input:58('t')
target expected output:1(' ')
<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int32, tf.int32)>
one
two
(64, 100, 65) #(batch_size,sequence_length,vocab_size)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_24 (Embedding)     (64, None, 256)           16640     
_________________________________________________________________
gru_24 (GRU)                 (64, None, 1024)          3935232   
_________________________________________________________________
dense_24 (Dense)             (64, None, 65)            66625     
=================================================================
Total params: 4,018,497
Trainable params: 4,018,497
Non-trainable params: 0
_________________________________________________________________
[20  5  6 22 12  2 16  5 27  8 32 64 50  2 20 47 34 42  3 33 61 39 10 43
  5 17 12 33 16 33  0 43 44 18 41 54 37  3 33 38 50  6 57  8 23 56  4 18
 28 23 17 23 35 58 24 23 43 17 46  1  2 49 44 17 21  8 54 49  3 47 18 26
 31 55 47 50 28 37 55  0  8 58 64 39  0 25 29 24  1 38 36 10  8 51 23  5
 26 57  8 22]
Input: 
 'th the wish of happy years:\nAs gentle and as jocund as to jest\nGo I to fight: truth hath a quiet bre'

Next Char Predictions: 
 "H',J?!D'O.Tzl!HiVd$Uwa:e'E?UDU\nefFcpY$UZl,s.Kr&FPKEKWtLKeEh !kfEI.pk$iFNSqilPYq\n.tza\nMQL ZX:.mK'Ns.J"
Prediction shape:  (64, 100, 65)  # (batch_size, sequence_length, vocab_size)
scalar_loss:       4.312578
debug1
debug2
Epoch 1/30
174/174 [==============================] - 1425s 8s/step - loss: 2.3770
Epoch 2/30
174/174 [==============================] - 1328s 8s/step - loss: 1.7776
Epoch 3/30
174/174 [==============================] - 1359s 8s/step - loss: 1.5740
Epoch 4/30
174/174 [==============================] - 1364s 8s/step - loss: 1.4620
Epoch 5/30
174/174 [==============================] - 1359s 8s/step - loss: 1.3916
Epoch 6/30
174/174 [==============================] - 3015s 17s/step - loss: 1.3379
Epoch 7/30
174/174 [==============================] - 1212s 7s/step - loss: 1.2890
Epoch 8/30
174/174 [==============================] - 1184s 7s/step - loss: 1.2499
Epoch 9/30
174/174 [==============================] - 1202s 7s/step - loss: 1.2084
Epoch 10/30
174/174 [==============================] - 1220s 7s/step - loss: 1.1704
Epoch 11/30
174/174 [==============================] - 1205s 7s/step - loss: 1.1286
Epoch 12/30
174/174 [==============================] - 1213s 7s/step - loss: 1.0866
Epoch 13/30
174/174 [==============================] - 2451s 14s/step - loss: 1.0464
Epoch 14/30
174/174 [==============================] - 1338s 8s/step - loss: 1.0069
Epoch 15/30
174/174 [==============================] - 1197s 7s/step - loss: 0.9685
Epoch 16/30
174/174 [==============================] - 1270s 7s/step - loss: 0.9331
Epoch 17/30
174/174 [==============================] - 1204s 7s/step - loss: 0.8987
Epoch 18/30
174/174 [==============================] - 1235s 7s/step - loss: 0.8711
Epoch 19/30
174/174 [==============================] - 1227s 7s/step - loss: 0.8452
Epoch 20/30
174/174 [==============================] - 1242s 7s/step - loss: 0.8210
Epoch 21/30
174/174 [==============================] - 1222s 7s/step - loss: 0.8017
Epoch 22/30
174/174 [==============================] - 1218s 7s/step - loss: 0.7811
Epoch 23/30
174/174 [==============================] - 1231s 7s/step - loss: 0.7654
Epoch 24/30
174/174 [==============================] - 1213s 7s/step - loss: 0.7495
Epoch 25/30
174/174 [==============================] - 1196s 7s/step - loss: 0.7368
Epoch 26/30
174/174 [==============================] - 5095s 29s/step - loss: 0.7251
Epoch 27/30
174/174 [==============================] - 1280s 7s/step - loss: 0.7105
Epoch 28/30
174/174 [==============================] - 1286s 7s/step - loss: 0.7028
Epoch 29/30
174/174 [==============================] - 1289s 7s/step - loss: 0.6914
Epoch 30/30
174/174 [==============================] - 1235s 7s/step - loss: 0.6831
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_25 (Embedding)     (1, None, 256)            16640     
_________________________________________________________________
gru_25 (GRU)                 (1, None, 1024)           3935232   
_________________________________________________________________
dense_25 (Dense)             (1, None, 65)             66625     
=================================================================
Total params: 4,018,497
Trainable params: 4,018,497
Non-trainable params: 0
_________________________________________________________________
debug3
debug4
ROMEO'MP yx?GQy$WkZG -Wpn&ahHJH3RCz$VsEQU vup-lsk&lnuO$sTWaq?IWSdAr&lM!MKCwkW
CJXu YDWzZMY'XHQzJBhKestWH.Z3UlXgWN,hZv?PaM;;pPSgCy3b'TM:$fyy'cZsCCB:Gf3;Plc;&zkP!FRK;JC&yjov3yjlcJ$lJ;q.&qJHfiC!ldweJqCa qgZq
YKMu;J:nMNZG$sxutkapPy$boZkPyGPm;;!$Z:CpxZ3WRyxQI;P!a 
HidHZIJYYvh&UdV!kael3h
MlJ HyDrNW$.SYcPna:RnLCUyv ZzPJ3JZkiywJN,LY$eupbfcpv&kPcYy;HJ;l!MTZhAQ Q;IaBaBsyxBhC$&fBuOlX3:W$?TCslCHwdkwKVJ?K!ke;KjwaQ$pYx;svWvEpWoVpZC;
py&DchKdJyhKcC&3pmUESYBklpfckMBQkycaXMx?PFyHbf;c$ biqwN&mcfyze:N.D3;bda:Z:pR?hMBX.RXYG$kOJhvw&bCWNdHx&zvyd3$wF;GUfjYiEQn&fJTAa$cNJJTkeU$n'yJR&jQIC$N$cQHK;.sSEbFCZ;O3NcwVa:rpHJGACezOyo&T:Q3$CSA$h$$$c'xImRt$ikJvgRJCy.wPrz&cX&CHWUeW&Nfy.lpE!y3wM$FrMBalFTZiaZvMyccRSWXIlalOnTjizuBC:wrXiCEfv
yLHByPJYI'TBJY!n3Ny33A;.zm$$r3Ca;..P$
yJ;NL$YWQ
:t?W&$B3IG!pp$aIwz;afy$FQbTNH&!RySkW?KlCWlRMWKcB sC$xJbw-npMgTc!MCQIqbfHK?yFzj.i$dmQwhQH&;Vkyw$bbP?3yqa?WYlCIwSb&3PM:QMX&mWKmJaY&plWxCJf's$MkZzz;3XSEPytDybHeIZvvK!dkpdclynYOJRYzC zr:yQ
k
TCFAN;?lOZZ.PyJFyZwcz
MCYJFnyJybo
MPzofMkaJ?OTd'AWRxbyCdSEln
END
